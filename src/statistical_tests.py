import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.stattools import adfuller, grangercausalitytests
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.stats.diagnostic import acorr_ljungbox
import os
import warnings
warnings.filterwarnings('ignore')

class StatisticalTests:
    """
    Module ki·ªÉm ƒë·ªãnh th·ªëng k√™ cho chu·ªói th·ªùi gian t√†i ch√≠nh.
    
    M·ª•c ƒë√≠ch:
    - Ki·ªÉm ƒë·ªãnh t√≠nh d·ª´ng (Stationarity) c·ªßa chu·ªói d·ªØ li·ªáu
    - Ki·ªÉm ƒë·ªãnh m·ªëi quan h·ªá nh√¢n qu·∫£ gi·ªØa c√°c bi·∫øn (Granger Causality)
    - X√°c ƒë·ªãnh s·ªë l∆∞·ª£ng lags t·ªëi ∆∞u th√¥ng qua ACF/PACF
    - Ki·ªÉm tra Residuals c√≥ ph·∫£i White Noise kh√¥ng
    """
    
    def __init__(self, results_dir=None):
        if results_dir is None:
            base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            self.results_dir = os.path.join(base_dir, "results", "figures")
        else:
            self.results_dir = results_dir
        os.makedirs(self.results_dir, exist_ok=True)
    
    def adf_test(self, series, name="Series"):
        """
        Augmented Dickey-Fuller Test - Ki·ªÉm ƒë·ªãnh t√≠nh d·ª´ng (Stationarity Test)
        
        Gi·∫£ thuy·∫øt:
        - H0 (Null Hypothesis): Chu·ªói c√≥ unit root (non-stationary) - KH√îNG d·ª´ng
        - H1 (Alternative): Chu·ªói l√† stationary - D·ª´ng
        
        Tham s·ªë:
        - series: Chu·ªói d·ªØ li·ªáu c·∫ßn ki·ªÉm ƒë·ªãnh (pandas Series)
        - name: T√™n c·ªßa chu·ªói ƒë·ªÉ hi·ªÉn th·ªã trong b√°o c√°o
        
        √ù nghƒ©a:
        - p-value < 0.05: B√°c b·ªè H0, chu·ªói l√† D·ª™NG ‚úì
        - p-value >= 0.05: Kh√¥ng b√°c b·ªè H0, chu·ªói KH√îNG D·ª™NG ‚úó
        
        T·∫°i sao quan tr·ªçng:
        - Chu·ªói kh√¥ng d·ª´ng (nh∆∞ gi√° c·ªï phi·∫øu) c√≥ mean/variance thay ƒë·ªïi theo th·ªùi gian
        - H·ªìi quy tr√™n chu·ªói kh√¥ng d·ª´ng d·∫´n ƒë·∫øn "spurious regression" (h·ªìi quy gi·∫£ m·∫°o)
        - Log Returns th∆∞·ªùng l√† d·ª´ng ‚Üí ph√π h·ª£p cho m√¥ h√¨nh ML
        """
        series_clean = series.dropna()
        
        try:
            result = adfuller(series_clean, autolag='AIC')
            
            adf_statistic = result[0]
            p_value = result[1]
            critical_values = result[4]
            
            print(f"\n{'='*70}")
            print(f"ADF TEST - {name}")
            print(f"{'='*70}")
            print(f"ADF Statistic:        {adf_statistic:.6f}")
            print(f"P-value:              {p_value:.6f}")
            print(f"\nCritical Values:")
            for key, value in critical_values.items():
                print(f"  {key:>4s}: {value:.4f}")
            
            # K·∫øt lu·∫≠n
            if p_value < 0.05:
                conclusion = f"‚úì Chu·ªñi '{name}' l√† STATIONARY (D·ª´ng) - p-value = {p_value:.6f} < 0.05"
                is_stationary = True
            else:
                conclusion = f"‚úó Chu·ªói '{name}' l√† NON-STATIONARY (Kh√¥ng d·ª´ng) - p-value = {p_value:.6f} >= 0.05"
                is_stationary = False
            
            print(f"\n{conclusion}")
            print(f"{'='*70}\n")
            
            # V·∫Ω bi·ªÉu ƒë·ªì Rolling Mean v√† Rolling Std ƒë·ªÉ minh h·ªça t√≠nh d·ª´ng
            self._plot_rolling_statistics(series_clean, name, is_stationary)
            
            return {
                'name': name,
                'adf_statistic': adf_statistic,
                'p_value': p_value,
                'critical_values': critical_values,
                'is_stationary': is_stationary,
                'conclusion': conclusion
            }
        except Exception as e:
            print(f"L·ªói khi th·ª±c hi·ªán ADF test cho {name}: {e}")
            return None
    
    def _plot_rolling_statistics(self, series, name, is_stationary):
        """
        V·∫Ω Rolling Mean v√† Rolling Std ƒë·ªÉ minh h·ªça t√≠nh d·ª´ng
        
        Chu·ªói d·ª´ng: Rolling mean v√† std ·ªïn ƒë·ªãnh theo th·ªùi gian
        Chu·ªói kh√¥ng d·ª´ng: Rolling mean/std thay ƒë·ªïi li√™n t·ª•c
        """
        plt.figure(figsize=(14, 8))
        
        # Original Series
        plt.subplot(3, 1, 1)
        plt.plot(series, label='Original Series', color='blue', alpha=0.7)
        plt.title(f'{name} - Original Series', fontsize=14, fontweight='bold')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # Rolling Mean
        rolling_mean = series.rolling(window=30).mean()
        plt.subplot(3, 1, 2)
        plt.plot(rolling_mean, label='Rolling Mean (30 days)', color='red', linewidth=2)
        plt.title('Rolling Mean - Ki·ªÉm tra xu h∆∞·ªõng thay ƒë·ªïi', fontsize=12)
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # Rolling Std
        rolling_std = series.rolling(window=30).std()
        plt.subplot(3, 1, 3)
        plt.plot(rolling_std, label='Rolling Std (30 days)', color='green', linewidth=2)
        plt.title('Rolling Standard Deviation - Ki·ªÉm tra bi·∫øn ƒë·ªông thay ƒë·ªïi', fontsize=12)
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        status = "STATIONARY ‚úì" if is_stationary else "NON-STATIONARY ‚úó"
        plt.suptitle(f'ADF Test: {name} - {status}', fontsize=16, fontweight='bold', y=0.995)
        
        plt.tight_layout()
        filename = f"adf_test_{name.lower().replace(' ', '_')}.png"
        plt.savefig(os.path.join(self.results_dir, filename), dpi=150, bbox_inches='tight')
        plt.close()
        print(f"   ‚Üí ƒê√£ l∆∞u bi·ªÉu ƒë·ªì: {filename}")
    
    def granger_causality_test(self, data, target_col, cause_col, max_lag=5):
        """
        Granger Causality Test - Ki·ªÉm ƒë·ªãnh nh√¢n qu·∫£ Granger
        
        M·ª•c ƒë√≠ch:
        Ki·ªÉm tra li·ªáu bi·∫øn X (cause_col) c√≥ "g√¢y ra" (predict) bi·∫øn Y (target_col) hay kh√¥ng
        
        Gi·∫£ thuy·∫øt:
        - H0: X KH√îNG Granger-cause Y (X kh√¥ng gi√∫p d·ª± b√°o Y)
        - H1: X Granger-cause Y (X c√≥ kh·∫£ nƒÉng d·ª± b√°o Y)
        
        Tham s·ªë:
        - data: DataFrame ch·ª©a c·∫£ hai c·ªôt
        - target_col: Bi·∫øn m·ª•c ti√™u (Y) - v√≠ d·ª•: 'Log_Returns'
        - cause_col: Bi·∫øn nguy√™n nh√¢n (X) - v√≠ d·ª•: 'Volume_Change'
        - max_lag: S·ªë lags t·ªëi ƒëa ƒë·ªÉ ki·ªÉm tra (default=5)
        
        √ù nghƒ©a t√†i ch√≠nh:
        - N·∫øu Volume Granger-cause Returns: Kh·ªëi l∆∞·ª£ng giao d·ªãch c√≥ th·ªÉ d·ª± b√°o bi·∫øn ƒë·ªông gi√°
        - ƒêi·ªÅu n√†y h·ªó tr·ª£ gi·∫£ thuy·∫øt: "Volume leads Price" trong technical analysis
        
        K·∫øt qu·∫£:
        - p-value < 0.05 t·∫°i lag k: Volume t·∫°i t-k c√≥ th·ªÉ d·ª± b√°o Returns t·∫°i t
        """
        print(f"\n{'='*70}")
        print(f"GRANGER CAUSALITY TEST")
        print(f"Nguy√™n nh√¢n (X): {cause_col} ‚Üí K·∫øt qu·∫£ (Y): {target_col}")
        print(f"{'='*70}")
        
        # Chu·∫©n b·ªã d·ªØ li·ªáu: Hai c·ªôt [target, cause]
        test_data = data[[target_col, cause_col]].dropna()
        
        if len(test_data) < max_lag + 10:
            print(f"Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ th·ª±c hi·ªán test (c·∫ßn √≠t nh·∫•t {max_lag + 10} ƒëi·ªÉm)")
            return None
        
        try:
            # Th·ª±c hi·ªán test
            gc_result = grangercausalitytests(test_data, maxlag=max_lag, verbose=False)
            
            # T·ªïng h·ª£p k·∫øt qu·∫£
            results_summary = []
            
            print(f"\n{'Lag':<6} {'F-stat':<12} {'P-value':<12} {'K·∫øt lu·∫≠n':<30}")
            print("-" * 70)
            
            for lag in range(1, max_lag + 1):
                # L·∫•y F-test result
                f_test = gc_result[lag][0]['ssr_ftest']
                f_stat = f_test[0]
                p_value = f_test[1]
                
                # K·∫øt lu·∫≠n
                if p_value < 0.05:
                    conclusion = f"‚úì {cause_col} C√ì Granger-cause {target_col}"
                    has_causality = True
                else:
                    conclusion = f"‚úó KH√îNG c√≥ Granger causality"
                    has_causality = False
                
                print(f"{lag:<6} {f_stat:<12.4f} {p_value:<12.6f} {conclusion}")
                
                results_summary.append({
                    'lag': lag,
                    'f_statistic': f_stat,
                    'p_value': p_value,
                    'has_causality': has_causality
                })
            
            print(f"{'='*70}\n")
            
            # V·∫Ω bi·ªÉu ƒë·ªì
            self._plot_granger_results(results_summary, cause_col, target_col)
            
            # Nh·∫≠n x√©t t·ªïng qu√°t
            significant_lags = [r['lag'] for r in results_summary if r['has_causality']]
            if significant_lags:
                print(f"üìä NH·∫¨N X√âT: {cause_col} c√≥ kh·∫£ nƒÉng d·ª± b√°o {target_col} t·∫°i c√°c lag: {significant_lags}")
                print(f"   ‚Üí √ù nghƒ©a: N√™n ƒë∆∞a {cause_col} v√†o m√¥ h√¨nh v·ªõi lag features {significant_lags}")
            else:
                print(f"üìä NH·∫¨N X√âT: KH√îNG t√¨m th·∫•y b·∫±ng ch·ª©ng th·ªëng k√™ cho m·ªëi quan h·ªá nh√¢n qu·∫£")
                print(f"   ‚Üí √ù nghƒ©a: {cause_col} c√≥ th·ªÉ kh√¥ng h·ªØu √≠ch cho vi·ªác d·ª± b√°o {target_col}")
            print()
            
            return results_summary
            
        except Exception as e:
            print(f"L·ªói khi th·ª±c hi·ªán Granger Causality Test: {e}")
            return None
    
    def _plot_granger_results(self, results_summary, cause_col, target_col):
        """V·∫Ω bi·ªÉu ƒë·ªì k·∫øt qu·∫£ Granger Causality Test"""
        lags = [r['lag'] for r in results_summary]
        p_values = [r['p_value'] for r in results_summary]
        
        plt.figure(figsize=(10, 6))
        
        # V·∫Ω p-values
        plt.bar(lags, p_values, color=['green' if p < 0.05 else 'red' for p in p_values], 
                alpha=0.7, edgecolor='black')
        
        # ƒê∆∞·ªùng significance level
        plt.axhline(y=0.05, color='blue', linestyle='--', linewidth=2, 
                   label='Significance Level (Œ±=0.05)')
        
        plt.xlabel('Lag', fontsize=12, fontweight='bold')
        plt.ylabel('P-value', fontsize=12, fontweight='bold')
        plt.title(f'Granger Causality Test: {cause_col} ‚Üí {target_col}\n' + 
                 f'(Green = C√≥ nh√¢n qu·∫£, Red = Kh√¥ng c√≥ nh√¢n qu·∫£)', 
                 fontsize=14, fontweight='bold')
        plt.legend(fontsize=10)
        plt.grid(True, alpha=0.3, axis='y')
        plt.xticks(lags)
        
        plt.tight_layout()
        filename = f"granger_causality_{cause_col.lower()}_{target_col.lower()}.png"
        plt.savefig(os.path.join(self.results_dir, filename), dpi=150, bbox_inches='tight')
        plt.close()
        print(f"   ‚Üí ƒê√£ l∆∞u bi·ªÉu ƒë·ªì: {filename}")
    
    def acf_pacf_analysis(self, series, name="Series", lags=40):
        """
        ACF/PACF Analysis - Ph√¢n t√≠ch t·ª± t∆∞∆°ng quan
        
        M·ª•c ƒë√≠ch:
        X√°c ƒë·ªãnh s·ªë l∆∞·ª£ng lags t·ªëi ∆∞u cho m√¥ h√¨nh ARIMA v√† lag features
        
        ACF (Autocorrelation Function):
        - ƒêo t∆∞∆°ng quan gi·ªØa y_t v√† y_{t-k}
        - Gi√∫p x√°c ƒë·ªãnh MA order (Moving Average)
        
        PACF (Partial Autocorrelation Function):
        - ƒêo t∆∞∆°ng quan gi·ªØa y_t v√† y_{t-k} SAU KHI lo·∫°i b·ªè ·∫£nh h∆∞·ªüng c·ªßa y_{t-1},...,y_{t-k+1}
        - Gi√∫p x√°c ƒë·ªãnh AR order (Autoregressive)
        
        Tham s·ªë:
        - series: Chu·ªói d·ªØ li·ªáu (pandas Series)
        - name: T√™n chu·ªói
        - lags: S·ªë l∆∞·ª£ng lags ƒë·ªÉ hi·ªÉn th·ªã (default=40)
        
        √ù nghƒ©a:
        - N·∫øu PACF significant ƒë·∫øn lag 5 ‚Üí S·ª≠ d·ª•ng 5 lag features trong m√¥ h√¨nh
        - N·∫øu ACF decay ch·∫≠m ‚Üí Chu·ªói c√≥ th·ªÉ kh√¥ng d·ª´ng
        """
        print(f"\n{'='*70}")
        print(f"ACF/PACF ANALYSIS - {name}")
        print(f"{'='*70}")
        
        series_clean = series.dropna()
        
        fig, axes = plt.subplots(2, 1, figsize=(14, 10))
        
        # ACF Plot
        plot_acf(series_clean, lags=lags, ax=axes[0], alpha=0.05)
        axes[0].set_title(f'ACF (Autocorrelation Function) - {name}\n' + 
                         'ƒêo t∆∞∆°ng quan gi·ªØa y_t v√† y_{t-k}', 
                         fontsize=13, fontweight='bold')
        axes[0].set_xlabel('Lag', fontsize=11)
        axes[0].set_ylabel('Correlation', fontsize=11)
        axes[0].grid(True, alpha=0.3)
        
        # PACF Plot
        plot_pacf(series_clean, lags=lags, ax=axes[1], alpha=0.05, method='ywm')
        axes[1].set_title(f'PACF (Partial Autocorrelation Function) - {name}\n' + 
                         'ƒêo t∆∞∆°ng quan SAU KHI lo·∫°i b·ªè ·∫£nh h∆∞·ªüng c·ªßa c√°c lag trung gian', 
                         fontsize=13, fontweight='bold')
        axes[1].set_xlabel('Lag', fontsize=11)
        axes[1].set_ylabel('Partial Correlation', fontsize=11)
        axes[1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        filename = f"acf_pacf_{name.lower().replace(' ', '_')}.png"
        plt.savefig(os.path.join(self.results_dir, filename), dpi=150, bbox_inches='tight')
        plt.close()
        print(f"   ‚Üí ƒê√£ l∆∞u bi·ªÉu ƒë·ªì: {filename}")
        
        # Ph√¢n t√≠ch v√† ƒë·ªÅ xu·∫•t s·ªë lags
        from statsmodels.tsa.stattools import acf, pacf
        acf_values = acf(series_clean, nlags=lags, fft=False)
        pacf_values = pacf(series_clean, nlags=lags, method='ywm')
        
        # T√¨m significant lags trong PACF (|value| > 1.96/sqrt(n))
        n = len(series_clean)
        threshold = 1.96 / np.sqrt(n)
        
        significant_lags_pacf = [i for i in range(1, lags+1) if abs(pacf_values[i]) > threshold]
        
        print(f"\nüìä PH√ÇN T√çCH K·∫æT QU·∫¢:")
        print(f"   - Significant lags trong PACF: {significant_lags_pacf[:10]}")  # Top 10
        print(f"   - Ng∆∞·ª°ng significance: ¬±{threshold:.4f}")
        
        if len(significant_lags_pacf) > 0:
            optimal_lags = significant_lags_pacf[:5]  # L·∫•y top 5
            print(f"\n   üí° ƒê·ªÄ XU·∫§T: S·ª≠ d·ª•ng {len(optimal_lags)} lag features: {optimal_lags}")
            print(f"      L√Ω do: C√°c lag n√†y c√≥ t∆∞∆°ng quan ri√™ng ph·∫ßn (PACF) v∆∞·ª£t ng∆∞·ª°ng significance")
        else:
            print(f"\n   üí° ƒê·ªÄ XU·∫§T: Chu·ªói c√≥ th·ªÉ l√† white noise ho·∫∑c s·ªë lags qu√° l·ªõn")
        
        print(f"{'='*70}\n")
        
        return {
            'name': name,
            'significant_lags': significant_lags_pacf,
            'optimal_lags': optimal_lags if len(significant_lags_pacf) > 0 else [1, 2, 3],
            'acf_values': acf_values,
            'pacf_values': pacf_values
        }
    
    def ljung_box_test(self, residuals, lags=10, name="Model"):
        """
        Ljung-Box Test - Ki·ªÉm ƒë·ªãnh White Noise cho Residuals
        
        M·ª•c ƒë√≠ch:
        Ki·ªÉm tra xem residuals (ph·∫ßn d∆∞) c·ªßa m√¥ h√¨nh c√≥ ph·∫£i l√† white noise kh√¥ng
        
        Gi·∫£ thuy·∫øt:
        - H0: Residuals l√† white noise (KH√îNG c√≥ autocorrelation)
        - H1: Residuals C√ì autocorrelation
        
        Tham s·ªë:
        - residuals: Ph·∫ßn d∆∞ c·ªßa m√¥ h√¨nh (y_true - y_pred)
        - lags: S·ªë lags ƒë·ªÉ ki·ªÉm tra
        - name: T√™n m√¥ h√¨nh
        
        √ù nghƒ©a:
        - p-value > 0.05: Residuals l√† white noise ‚úì
          ‚Üí M√¥ h√¨nh ƒë√£ tr√≠ch xu·∫•t H·∫æT th√¥ng tin t·ª´ d·ªØ li·ªáu
        - p-value < 0.05: Residuals C√ì c·∫•u tr√∫c t·ª± t∆∞∆°ng quan ‚úó
          ‚Üí M√¥ h√¨nh c√≤n b·ªè s√≥t th√¥ng tin, c·∫ßn c·∫£i thi·ªán
        
        T·∫°i sao quan tr·ªçng:
        - Residuals c√≥ autocorrelation nghƒ©a l√† m√¥ h√¨nh ch∆∞a t·ªëi ∆∞u
        - C√≥ th·ªÉ c·∫ßn th√™m features ho·∫∑c thay ƒë·ªïi c·∫•u tr√∫c m√¥ h√¨nh
        """
        print(f"\n{'='*70}")
        print(f"LJUNG-BOX TEST (WHITE NOISE TEST) - {name}")
        print(f"{'='*70}")
        
        residuals_clean = residuals.dropna()
        
        if len(residuals_clean) < lags + 10:
            print("Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ th·ª±c hi·ªán Ljung-Box test")
            return None
        
        try:
            # Th·ª±c hi·ªán test
            lb_result = acorr_ljungbox(residuals_clean, lags=lags, return_df=True)
            
            print(f"\n{'Lag':<6} {'LB Statistic':<15} {'P-value':<12} {'K·∫øt lu·∫≠n':<30}")
            print("-" * 70)
            
            all_white_noise = True
            
            for i, row in lb_result.iterrows():
                lag = i + 1
                lb_stat = row['lb_stat']
                p_val = row['lb_pvalue']
                
                if p_val > 0.05:
                    conclusion = "‚úì White Noise (T·ªët)"
                else:
                    conclusion = "‚úó C√≥ autocorrelation (Ch∆∞a t·ªëi ∆∞u)"
                    all_white_noise = False
                
                print(f"{lag:<6} {lb_stat:<15.4f} {p_val:<12.6f} {conclusion}")
            
            print(f"{'='*70}")
            
            # K·∫øt lu·∫≠n t·ªïng qu√°t
            if all_white_noise:
                print(f"\n‚úì K·∫æT LU·∫¨N: Residuals c·ªßa {name} l√† WHITE NOISE")
                print(f"  ‚Üí M√¥ h√¨nh ƒë√£ tr√≠ch xu·∫•t h·∫øt th√¥ng tin c√≥ th·ªÉ t·ª´ d·ªØ li·ªáu")
                print(f"  ‚Üí Kh√¥ng c·∫ßn th√™m features ho·∫∑c lags")
            else:
                print(f"\n‚úó K·∫æT LU·∫¨N: Residuals c·ªßa {name} C√ì AUTOCORRELATION")
                print(f"  ‚Üí M√¥ h√¨nh ch∆∞a t·ªëi ∆∞u, c√≤n b·ªè s√≥t th√¥ng tin")
                print(f"  ‚Üí ƒê·ªÅ xu·∫•t: Th√™m lag features, th·ª≠ m√¥ h√¨nh ph·ª©c t·∫°p h∆°n (LSTM/ARIMA)")
            print()
            
            # V·∫Ω bi·ªÉu ƒë·ªì residuals
            self._plot_residuals_analysis(residuals_clean, lb_result, name)
            
            return lb_result
            
        except Exception as e:
            print(f"L·ªói khi th·ª±c hi·ªán Ljung-Box test: {e}")
            return None
    
    def _plot_residuals_analysis(self, residuals, lb_result, name):
        """V·∫Ω bi·ªÉu ƒë·ªì ph√¢n t√≠ch Residuals"""
        fig, axes = plt.subplots(3, 1, figsize=(14, 12))
        
        # 1. Residuals over time
        axes[0].plot(residuals, color='blue', alpha=0.6)
        axes[0].axhline(y=0, color='red', linestyle='--', linewidth=2)
        axes[0].set_title(f'Residuals Over Time - {name}\n(N√™n dao ƒë·ªông quanh 0 n·∫øu m√¥ h√¨nh t·ªët)', 
                         fontsize=13, fontweight='bold')
        axes[0].set_ylabel('Residuals', fontsize=11)
        axes[0].grid(True, alpha=0.3)
        
        # 2. Distribution of Residuals
        axes[1].hist(residuals, bins=50, color='green', alpha=0.7, edgecolor='black')
        axes[1].set_title('Ph√¢n ph·ªëi Residuals\n(N√™n c√≥ d·∫°ng chu·∫©n - h√¨nh chu√¥ng)', 
                         fontsize=13, fontweight='bold')
        axes[1].set_xlabel('Residual Value', fontsize=11)
        axes[1].set_ylabel('Frequency', fontsize=11)
        axes[1].grid(True, alpha=0.3, axis='y')
        
        # 3. Ljung-Box p-values
        lags = range(1, len(lb_result) + 1)
        p_values = lb_result['lb_pvalue'].values
        
        colors = ['green' if p > 0.05 else 'red' for p in p_values]
        axes[2].bar(lags, p_values, color=colors, alpha=0.7, edgecolor='black')
        axes[2].axhline(y=0.05, color='blue', linestyle='--', linewidth=2, 
                       label='Significance Level (Œ±=0.05)')
        axes[2].set_title('Ljung-Box Test P-values\n(Green = White Noise ‚úì, Red = Autocorrelation ‚úó)', 
                         fontsize=13, fontweight='bold')
        axes[2].set_xlabel('Lag', fontsize=11)
        axes[2].set_ylabel('P-value', fontsize=11)
        axes[2].legend(fontsize=10)
        axes[2].grid(True, alpha=0.3, axis='y')
        
        plt.tight_layout()
        filename = f"residuals_analysis_{name.lower().replace(' ', '_')}.png"
        plt.savefig(os.path.join(self.results_dir, filename), dpi=150, bbox_inches='tight')
        plt.close()
        print(f"   ‚Üí ƒê√£ l∆∞u bi·ªÉu ƒë·ªì: {filename}")


def run_all_statistical_tests():
    """
    Ch·∫°y t·∫•t c·∫£ c√°c ki·ªÉm ƒë·ªãnh th·ªëng k√™ tr√™n d·ªØ li·ªáu FPT
    
    Pipeline:
    1. Load d·ªØ li·ªáu preprocessed
    2. ADF Test cho Close v√† Log_Returns
    3. Granger Causality Test (Volume ‚Üí Returns)
    4. ACF/PACF Analysis cho Log_Returns
    
    K·∫øt qu·∫£:
    - C√°c bi·ªÉu ƒë·ªì ƒë∆∞·ª£c l∆∞u trong results/figures/
    - K·∫øt qu·∫£ ƒë∆∞·ª£c in ra console v·ªõi gi·∫£i th√≠ch chi ti·∫øt
    """
    print("\n" + "="*80)
    print(" " * 20 + "STATISTICAL TESTS - FPT STOCK ANALYSIS")
    print("="*80 + "\n")
    
    # Load data
    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    data_file = os.path.join(base_dir, "data", "processed", "preprocessed_data.csv")
    
    if not os.path.exists(data_file):
        print(f"L·ªói: Kh√¥ng t√¨m th·∫•y file {data_file}")
        print("Vui l√≤ng ch·∫°y preprocess_data.py tr∆∞·ªõc")
        return
    
    df = pd.read_csv(data_file, index_col='Date', parse_dates=True)
    print(f"‚úì ƒê√£ load d·ªØ li·ªáu: {len(df)} ƒëi·ªÉm d·ªØ li·ªáu\n")
    
    # Kh·ªüi t·∫°o test module
    tester = StatisticalTests()
    
    # 1. ADF Test
    print("\n" + "‚ñà"*80)
    print("PH·∫¶N 1: KI·ªÇM ƒê·ªäNH T√çNH D·ª™NG (STATIONARITY TEST)")
    print("‚ñà"*80)
    
    adf_close = tester.adf_test(df['Close'], name="Close Price")
    adf_returns = tester.adf_test(df['Log_Returns'], name="Log Returns")
    
    # 2. Granger Causality Tests - Ki·ªÉm tra nhi·ªÅu c·∫∑p features
    print("\n" + "‚ñà"*80)
    print("PH·∫¶N 2: KI·ªÇM ƒê·ªäNH NH√ÇN QU·∫¢ GRANGER (CAUSALITY TEST)")
    print("‚ñà"*80)
    
    # T·∫°o c√°c features n·∫øu ch∆∞a c√≥
    if 'Volume_Change' not in df.columns:
        df['Volume_Change'] = df['Volume'].pct_change()
    
    # Dictionary l∆∞u k·∫øt qu·∫£ t·∫•t c·∫£ Granger tests
    granger_results = {}
    
    # Test 1: Volume_Change ‚Üí Log_Returns
    print("\n--- Test 1: Volume_Change ‚Üí Log_Returns ---")
    gc_volume = tester.granger_causality_test(
        df, 
        target_col='Log_Returns', 
        cause_col='Volume_Change',
        max_lag=5
    )
    granger_results['Volume_Change'] = gc_volume
    
    # Test 2: RSI_14 ‚Üí Log_Returns
    if 'RSI_14' in df.columns:
        print("\n--- Test 2: RSI_14 ‚Üí Log_Returns ---")
        gc_rsi = tester.granger_causality_test(
            df, 
            target_col='Log_Returns', 
            cause_col='RSI_14',
            max_lag=5
        )
        granger_results['RSI_14'] = gc_rsi
    
    # Test 3: Volatility_30 ‚Üí Log_Returns
    if 'Volatility_30' in df.columns:
        print("\n--- Test 3: Volatility_30 ‚Üí Log_Returns ---")
        gc_volatility = tester.granger_causality_test(
            df, 
            target_col='Log_Returns', 
            cause_col='Volatility_30',
            max_lag=5
        )
        granger_results['Volatility_30'] = gc_volatility
    
    # Test 4: MACD ‚Üí Log_Returns
    if 'MACD_12_26_9' in df.columns:
        print("\n--- Test 4: MACD_12_26_9 ‚Üí Log_Returns ---")
        gc_macd = tester.granger_causality_test(
            df, 
            target_col='Log_Returns', 
            cause_col='MACD_12_26_9',
            max_lag=5
        )
        granger_results['MACD_12_26_9'] = gc_macd
    
    # T·ªïng h·ª£p k·∫øt qu·∫£ Granger Causality
    print("\n" + "="*80)
    print(" " * 20 + "T·ªîNG H·ª¢P K·∫æT QU·∫¢ GRANGER CAUSALITY")
    print("="*80)
    print(f"\n{'Feature':<20} {'C√≥ nh√¢n qu·∫£?':<15} {'Significant Lags':<20} {'ƒê·ªÅ xu·∫•t':<30}")
    print("-" * 85)
    
    features_to_keep = []
    features_to_remove = []
    
    for feature_name, result in granger_results.items():
        if result:
            significant_lags = [r['lag'] for r in result if r['has_causality']]
            has_causality = len(significant_lags) > 0
            
            if has_causality:
                status = "‚úì C√ì"
                suggestion = f"GI·ªÆ L·∫†I (lag {significant_lags})"
                features_to_keep.append(feature_name)
            else:
                status = "‚úó KH√îNG"
                suggestion = "XEM X√âT LO·∫†I B·ªé"
                features_to_remove.append(feature_name)
            
            print(f"{feature_name:<20} {status:<15} {str(significant_lags):<20} {suggestion:<30}")
    
    print("-" * 85)
    print(f"\nüìä ƒê·ªÄ XU·∫§T FEATURE SELECTION:")
    if features_to_keep:
        print(f"   ‚úì Features N√äN GI·ªÆ: {features_to_keep}")
    if features_to_remove:
        print(f"   ‚ö† Features C√ÇN NH·∫ÆC LO·∫†I: {features_to_remove}")
    print()
    
    # 3. ACF/PACF Analysis
    print("\n" + "‚ñà"*80)
    print("PH·∫¶N 3: PH√ÇN T√çCH ACF/PACF (OPTIMAL LAGS DETERMINATION)")
    print("‚ñà"*80)
    
    acf_result = tester.acf_pacf_analysis(df['Log_Returns'], name="Log Returns", lags=40)
    
    print("\n" + "="*80)
    print(" " * 25 + "HO√ÄN TH√ÄNH T·∫§T C·∫¢ KI·ªÇM ƒê·ªäNH")
    print("="*80)
    print(f"\n‚úì T·∫•t c·∫£ bi·ªÉu ƒë·ªì ƒë√£ ƒë∆∞·ª£c l∆∞u trong: {tester.results_dir}")
    print("\nK·∫øt qu·∫£ t√≥m t·∫Øt:")
    print(f"  1. Close Price: {'D·ª´ng ‚úì' if adf_close['is_stationary'] else 'KH√îNG d·ª´ng ‚úó'}")
    print(f"  2. Log Returns: {'D·ª´ng ‚úì' if adf_returns['is_stationary'] else 'KH√îNG d·ª´ng ‚úó'}")
    
    # Hi·ªÉn th·ªã Granger results cho t·ª´ng feature
    print(f"  3. Granger Causality Tests:")
    for feature_name, result in granger_results.items():
        if result:
            has_causality = any(r['has_causality'] for r in result)
            status = 'C√≥ nh√¢n qu·∫£ ‚úì' if has_causality else 'KH√îNG c√≥ nh√¢n qu·∫£ ‚úó'
            print(f"     - {feature_name} ‚Üí Returns: {status}")
    
    print(f"  4. Optimal lags: {acf_result['optimal_lags']}")
    print(f"  5. Features n√™n gi·ªØ: {features_to_keep if features_to_keep else 'Kh√¥ng c√≥'}")
    print(f"  6. Features c√¢n nh·∫Øc lo·∫°i: {features_to_remove if features_to_remove else 'Kh√¥ng c√≥'}")
    print()


if __name__ == "__main__":
    run_all_statistical_tests()
